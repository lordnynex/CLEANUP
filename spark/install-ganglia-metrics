#!/bin/bash
# Configures Spark Ganglia metrics 
#
# script [masterip] [port]
#    [masterip] may be "master" to designate use the cluster's master node ip, if port is given, masterip must be given
# expects ganlgia and spark to already be installed by prior bootstrap actions
set -x
#
MASTER="master"
MASTERIP=`grep /home/hadoop/conf/yarn-site.xml -e yarn\.resourcemanager\.address | cut -d ':' -f1 | cut -d '>' -f5`
PORT=8649

#determine the current region and place into REGION
EC2AZ=$(curl -s http://169.254.169.254/latest/meta-data/placement/availability-zone)
REGION="`echo \"$EC2AZ\" | sed -e 's:\([0-9][0-9]*\)[a-z]*\$:\\1:'`"


if [ "$SparkS3SupportingFilesPath" == "" ]
then
       if [ "$REGION" == "eu-central-1" ]
       then
               SparkS3SupportingFilesPath=s3://eu-central-1.support.elasticmapreduce/spark
       else
               SparkS3SupportingFilesPath=s3://support.elasticmapreduce/spark
       fi
fi
SparkS3SupportingFilesPath=${SparkS3SupportingFilesPath%/}
	

if [ $# -eq 2 ]
then
	PORT=$2
	MASTER=$1
fi

if [  $# -eq 1 ]
then
	MASTER=$1
fi

if [ "$MASTER" != "master" ]
then
	MASTERIP=$MASTER
fi


echo "Configuring Spark Ganglia configuration to use Ganglia master IP $MASTERIP and port $PORT"

cat << EOF > /home/hadoop/spark/conf/ganglia.metrics.properties

*.sink.ganglia.class=org.apache.spark.metrics.sink.GangliaSink
*.sink.ganglia.name=AMZN-EMR
*.sink.ganglia.host=$MASTERIP
*.sink.ganglia.port=$PORT

*.sink.ganglia.mode=unicast
*.sink.ganglia.period=10
*.sink.ganglia.unit=seconds

EOF

hadoop fs -get "$SparkS3SupportingFilesPath/configure-spark.bash"

bash configure-spark.bash spark.metrics.conf=/home/hadoop/spark/conf/ganglia.metrics.properties

#restart local gmond and gmetad if present
sudo pkill gmeta
sudo pkill gmond

CONF_FILE=/etc/ganglia/gmond.conf
if [ -e /etc/gmond.conf ]
then
    CONF_FILE=/etc/gmond.conf
fi

sudo /usr/sbin/gmond -c $CONF_FILE

exit 0
